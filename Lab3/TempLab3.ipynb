{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevation Interpolation and Accuracy Assessment\n",
    "\n",
    "###### Help provided by ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import arcpy\n",
    "import psycopg2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:34:52 PM\",\"Succeeded at Friday, March 15, 2024 10:34:54 PM (Elapsed Time: 1.98 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.gdb'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#location to current directory (relative path)\n",
    "file_path = os.path.dirname(arcpy.mp.ArcGISProject('CURRENT').filePath)\n",
    "os.chdir(file_path)\n",
    "#absolute path for geodatabase\n",
    "arcpy.env.workspace = file_path\n",
    "arcpy.management.CreateFileGDB(file_path, \"Lab3.gdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1: Connection to database\n",
    "database_key = 'loganandgreg'\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"gis5572\",\n",
    "    user=\"postgres\",\n",
    "    password=database_key,\n",
    "    host=\"35.232.21.197\",\n",
    "    port=\"5432\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "#saving created datasets\n",
    "output_feature_class = \"TempLab3\"\n",
    "output_database = \"Lab3.gdb\"\n",
    "#create an empty feature class (stores retrieved data)\n",
    "arcpy.CreateFeatureclass_management(output_database, output_feature_class, \"POINT\", spatial_reference=arcpy.SpatialReference(4326))\n",
    "#add fields to store WKT geometry (latitude/longitude of points) and grid code (value of cell)\n",
    "arcpy.AddField_management(output_feature_class, \"WKT_GEOM\", \"TEXT\")\n",
    "arcpy.AddField_management(output_feature_class, \"GRID_CODE\", \"FLOAT\")\n",
    "#cursor is interaction to database (allows us to make SQL statements)\n",
    "cur = conn.cursor()\n",
    "#SQL query to retrieve data from the table as temperature and longitude and latitude as WKT (in that order)\n",
    "#pulling data for one data (maximum temperature data for one date)\n",
    "select_query = \"\"\"SELECT value_tmax, CONCAT('POINT(', longitude, ' ', latitude, ')') AS WKT\n",
    "FROM temp_data\n",
    "WHERE date = '2023-12-20T00:00:00';\"\"\"\n",
    "#execute SQL query\n",
    "cur.execute(select_query)\n",
    "#inserting using arcpy.da.Insert: SHAPE@WKT is the actual point, WKT_GEOM is storing coordinates, GRID_Code value of raster cell-- stores in output (TempLab3)\n",
    "with arcpy.da.InsertCursor(output_feature_class, [\"SHAPE@WKT\", \"WKT_GEOM\", \"GRID_CODE\"]) as cursor:\n",
    "    #fetch all rows in table returned from SQL\n",
    "    rows = cur.fetchall()\n",
    "    #print(len(rows))-- this was to test that I had the right about of rows\n",
    "    #retrieved data\n",
    "    for row in rows:\n",
    "        wkt_geom = row[1] #this is wkt_geom (first index)\n",
    "        grid_code = row[0] #this is grid_code (second index)\n",
    "        #insert the row into the output feature class (TempLab3)\n",
    "        cursor.insertRow([wkt_geom, wkt_geom, grid_code])\n",
    "#close the cursor/database connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Data\n",
    "\n",
    "#### Justification: 90/10 Split\n",
    "##### By allocating 90% of the data for training, the model has enough data to learn from the underlying patterns and relationships. Additionally, a larger training model can reduce bias in the model. More data means better models. The 10% sample is good for examining generalizations within datasets, as it learns relevant patterns without overfitting to the training data. This training-testing split ratio overall is good for model evaluation and model validation, as elevation has a lot of variance and a larger dataset can identify and interpret anomalies and classify the remaining data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled features have been saved to RandomSampledFeatures2\n",
      "Remaining features have been saved to RemainingFeatures2\n"
     ]
    }
   ],
   "source": [
    "#input feature class and output feature classes\n",
    "input_feature_class = \"TempLab3\"\n",
    "#10% - Testing Dataset\n",
    "output_sample_fc = \"RandomSampledFeatures2\"\n",
    "#90% - Training data\n",
    "output_remaining_fc = \"RemainingFeatures2\"\n",
    "#gets the number of features in the input class starting at index 0 as an integer (counts rows)\n",
    "total_count = int(arcpy.GetCount_management(input_feature_class)[0])\n",
    "#create empty list to store each row we want to subset (stores all data)\n",
    "all_features = []\n",
    "#creates search cursor to iterate through the input feature class (store as list and shuffle data at random) (copy of dataset)\n",
    "with arcpy.da.SearchCursor(input_feature_class, [\"SHAPE@WKT\", \"GRID_CODE\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        #extract WKT geometry and temperature (grid_code)\n",
    "        wkt_geometry = row[0]\n",
    "        Temp = row[1]\n",
    "        #append WKT geometry and elevation to the all features list\n",
    "        all_features.append((wkt_geometry, Temp))\n",
    "#randomize data\n",
    "random.shuffle(all_features)\n",
    "#calculate sample size (10%)\n",
    "sample_size = int(total_count * 0.1)\n",
    "#split the shuffled list into sampled features and remaining features\n",
    "sampled_features = all_features[:sample_size]\n",
    "remaining_features = all_features[sample_size:]\n",
    "#create a new feature class to store the random sample as a point feature class\n",
    "arcpy.CreateFeatureclass_management(arcpy.env.workspace, output_sample_fc, \"POINT\", spatial_reference=arcpy.Describe(input_feature_class).spatialReference)\n",
    "#create new field titled elevation\n",
    "arcpy.AddField_management(output_sample_fc, \"Temp\", \"DOUBLE\")\n",
    "#insert the randomly sampled features into the output sample feature class\n",
    "with arcpy.da.InsertCursor(output_sample_fc, [\"SHAPE@WKT\", \"Temp\"]) as cursor:\n",
    "    for wkt_geometry, Temp in sampled_features:\n",
    "        cursor.insertRow((wkt_geometry, Temp))\n",
    "print(\"Randomly sampled features have been saved to\", output_sample_fc)\n",
    "#create a new feature class to store the remaining features\n",
    "arcpy.CreateFeatureclass_management(arcpy.env.workspace, output_remaining_fc, \"POINT\", spatial_reference=arcpy.Describe(input_feature_class).spatialReference)\n",
    "#add fields to the output remaining feature class\n",
    "arcpy.AddField_management(output_remaining_fc, \"Temp\", \"DOUBLE\")\n",
    "#insert the remaining features into the output remaining feature class\n",
    "with arcpy.da.InsertCursor(output_remaining_fc, [\"SHAPE@WKT\", \"Temp\"]) as cursor:\n",
    "    for wkt_geometry, Temp in remaining_features:\n",
    "        cursor.insertRow((wkt_geometry, Temp))\n",
    "print(\"Remaining features have been saved to\", output_remaining_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:38:12 PM\",\"Calculating Kernel Interpolation\",\"Calculating Universal Kriging – Default\",\"Calculating Universal Kriging – Optimized\",\"Calculating Inverse Distance Weighted - Default\",\"Calculating Inverse Distance Weighted - Optimized\",\" \\n\",\"--------------------------------------------\",\"RANK | NAME\",\"--------------------------------------------\",\"\\n\",\"1    | Universal Kriging – Optimized\",\"\\n\",\"2    | Kernel Interpolation\",\"\\n\",\"3    | Inverse Distance Weighted - Optimized\",\"\\n\",\"4    | Universal Kriging – Default\",\"\\n\",\"5    | Inverse Distance Weighted - Default\",\"--------------------------------------------\",\"Succeeded at Friday, March 15, 2024 10:38:17 PM (Elapsed Time: 5.08 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.gdb\\\\exploratoryinterpolation2'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use training data to perform analysis\n",
    "#\"Generates various interpolation results from input point features and a field. The interpolation results are then compared and ranked using customizable criteria based on cross validation statistics (ESRI, 2024).\"\n",
    "arcpy.ga.ExploratoryInterpolation(\n",
    "    in_features=\"RemainingFeatures2\",\n",
    "    value_field=\"Temp\",\n",
    "    out_cv_table= (arcpy.env.workspace + \"\\\\Lab3.gdb\\\\exploratoryinterpolation2\"),\n",
    "    out_geostat_layer=None,\n",
    "    interp_methods=\"KERNEL_INTERPOLATION;UNIVERSAL_KRIGING;IDW\",\n",
    "    comparison_method=\"SINGLE\",\n",
    "    criterion=\"ACCURACY\",\n",
    "    criteria_hierarchy=\"ACCURACY PERCENT #\",\n",
    "    weighted_criteria=\"ACCURACY 1\",\n",
    "    exclusion_criteria=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "\n",
    "Definitions: \n",
    "\n",
    "Kriging: \"An interpolation technique in which the surrounding measured values are weighted to derive a predicted value for an unmeasured location. Weights are based on the distance between the measured points, the prediction locations, and the overall spatial arrangement among the measured points (ESRI, 2024).\"\n",
    "\n",
    "KernelInterpolationWtihBarriers: \"A moving window predictor that uses the shortest distance between points so that points on either side of the line barriers are connected.Kernel Interpolation is a variant of a first-order Local Polynomial Interpolation in which instability in the calculations is prevented using a method similar to the one used in the ridge regression to estimate the regression coefficients (ESRI, 2024).\"\n",
    "\n",
    "Inverse distance weighted: \"(IDW) interpolation determines cell values using a linearly weighted combination of a set of sample points. The weight is a function of inverse distance. The surface being interpolated should be that of a locationally dependent variable (ESRI, 2024).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:43:15 PM\",\"Succeeded at Friday, March 15, 2024 10:43:21 PM (Elapsed Time: 6.73 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result ''>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kriging\n",
    "Kriging_Temp = arcpy.sa.Kriging(\n",
    "    in_point_features=\"RemainingFeatures2\",\n",
    "    z_field=\"Temp\",\n",
    "    kriging_model=\"LinearDrift 0.021788 # # #\",\n",
    "    cell_size=0.1,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    out_variance_prediction_raster=None\n",
    ")\n",
    "\n",
    "#kernel\n",
    "arcpy.ga.KernelInterpolationWithBarriers(\n",
    "    in_features=\"RemainingFeatures2\",\n",
    "    z_field=\"Temp\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=arcpy.env.workspace + \"\\\\ArcIILab2.gdb\\\\Kernel_Temp\",\n",
    "    cell_size=0.1,\n",
    "    in_barrier_features=None,\n",
    "    kernel_function=\"POLYNOMIAL5\",\n",
    "    bandwidth=None,\n",
    "    power=1,\n",
    "    ridge=50,\n",
    "    output_type=\"PREDICTION\"\n",
    ")\n",
    "\n",
    "#IDW\n",
    "arcpy.ga.IDW(\n",
    "    in_features=\"RemainingFeatures2\",\n",
    "    z_field=\"Temp\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=arcpy.env.workspace + \"\\\\ArcIILab2.gdb\\\\IDW_Temp\",\n",
    "    cell_size=0.1,\n",
    "    power=2,\n",
    "    search_neighborhood=\"NBRTYPE=Standard S_MAJOR=2.19318511074646 S_MINOR=2.19318511074646 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "    weight_field=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:43:35 PM\",\"WARNING 000258: Output C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.sde already exists\",\"Succeeded at Friday, March 15, 2024 10:43:46 PM (Elapsed Time: 10.75 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.sde'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create connection to cloud database (On google cloud-- SQL database)\n",
    "out_folder_path = arcpy.env.workspace\n",
    "out_name = \"Lab3.sde\"\n",
    "database_platform = \"POSTGRESQL\"\n",
    "instance = \"35.232.21.197\"\n",
    "account_authentication = \"DATABASE_AUTH\"\n",
    "username = \"postgres\"\n",
    "password = \"loganandgreg\"\n",
    "save_user_pass = \"SAVE_USERNAME\"\n",
    "database = \"gis5572\"\n",
    "#actual database connection\n",
    "arcpy.management.CreateDatabaseConnection(out_folder_path, out_name, database_platform, instance, account_authentication, username, password, save_user_pass, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves Interpolated Maps and Exploratory Table to Geodatabase and POSTGIS (PostGres Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:49:15 PM\",\"Kernel_Temp_Point Successfully converted:  C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.sde\\\\Kernel_Temp_Point\",\"Succeeded at Friday, March 15, 2024 10:51:43 PM (Elapsed Time: 2 minutes 27 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.sde'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converts IDW interpolated map to point\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"IDW_Temp\",\n",
    "    out_point_features= (arcpy.env.workspace + \"\\\\IDW_Temp_Point\"),\n",
    "    raster_field=\"Value\"\n",
    ")\n",
    "#saves IDW interpolated points to database\n",
    "arcpy.conversion.FeatureClassToGeodatabase(\n",
    "    Input_Features=\"IDW_Temp_Point\",\n",
    "    Output_Geodatabase= (arcpy.env.workspace + \"\\\\Lab3.sde\")\n",
    ")\n",
    "#converts Kriging interpolated map to point\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"Kriging_Temp\",\n",
    "    out_point_features= (arcpy.env.workspace + \"\\\\Kriging_Temp_Point\"),\n",
    "    raster_field=\"Value\"\n",
    ")\n",
    "#saves Kriging interpolated points to database\n",
    "arcpy.conversion.FeatureClassToGeodatabase(\n",
    "    Input_Features=\"Kriging_Temp_Point\",\n",
    "    Output_Geodatabase= (arcpy.env.workspace + \"\\\\Lab3.sde\")\n",
    ")\n",
    "#converts Kernel interpolated map to point\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=\"Kernel_Temp\",\n",
    "    out_point_features= (arcpy.env.workspace + \"\\\\Kernel_Temp_Point\"),\n",
    "    raster_field=\"Value\"\n",
    ")\n",
    "#saves Kernel interpolated points to database\n",
    "arcpy.conversion.FeatureClassToGeodatabase(\n",
    "    Input_Features=\"Kernel_Temp_Point\",\n",
    "    Output_Geodatabase= (arcpy.env.workspace + \"\\\\Lab3.sde\")\n",
    ")\n",
    "#saves exploratory table\n",
    "arcpy.conversion.TableToGeodatabase(\n",
    "    Input_Table=\"\\\\Lab3.gdb\\\\exploratoryinterpolation2\",\n",
    "    Output_Geodatabase= (arcpy.env.workspace + \"\\\\Lab3.sde\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Assessment\n",
    "#### Perform Accuracy Assessment on the testing 10% of data compared to the most accurate Interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#stores difference in ground truth (comparing interpolation estimate to actual point data) \n",
    "#kriging was best-- as exploration interpolation choose (highest accuracy in leave one out cross validation)\n",
    "#defining paths\n",
    "input_point_dataset = arcpy.env.workspace + \"\\\\RandomSampledFeatures2\" \n",
    "input_raster = arcpy.env.workspace + \"\\\\Kriging_Temp\"  \n",
    "output_point_dataset = arcpy.env.workspace + \"\\\\Temp_Accuracy\"  \n",
    "#step 1: Copy the point dataset (10%)\n",
    "arcpy.CopyFeatures_management(input_point_dataset, output_point_dataset)\n",
    "#step 2: Extract raster values to the copied points dataset\n",
    "#field is value in our interpolation outputs and taking that field and extracting those values into a point dataset\n",
    "#interpolation raster set + 10% test sample together into one dataset --two columns to directly subtract\n",
    "extracted_field_name = \"VALUE\"  \n",
    "arcpy.sa.ExtractValuesToPoints(\n",
    "    in_point_features=\"RandomSampledFeatures2\",\n",
    "    in_raster=\"Kriging_Temp\",\n",
    "    out_point_features= arcpy.env.workspace + \"\\\\Temp_Accuracy\",\n",
    "    interpolate_values=\"NONE\",\n",
    "    add_attributes=\"VALUE_ONLY\"\n",
    ")\n",
    "#names of columns\n",
    "    ##temp: (testing data)\n",
    "    ##RASTERVALU (interpolation data we pulled)\n",
    "    ##Diff_Value (new field) (elevation minus RASTERVALU)\n",
    "    ##this is prep to calculate for Diff_Value\n",
    "point_value_field = \"Temp\"  \n",
    "difference_field = \"Diff_Value\"  \n",
    "extracted_field_name = \"RASTERVALU\"\n",
    "#step 3: add a new field for the difference (aka calculate)\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=\"Temp_Accuracy\",\n",
    "    field=\"Diff_Value\",\n",
    "    expression=\"!Temp!-!RASTERVALU!\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"LONG\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    ")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves Accuracy Assessment to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:56:22 PM\",\"Temp_Accuracy Successfully converted:  C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.sde\\\\Temp_Accuracy\",\"Succeeded at Friday, March 15, 2024 10:56:36 PM (Elapsed Time: 14.20 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Track\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\ArcIILab2\\\\Lab3.sde'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saves to database\n",
    "arcpy.conversion.FeatureClassToGeodatabase(\n",
    "    Input_Features=\"Temp_Accuracy\",\n",
    "    Output_Geodatabase= (arcpy.env.workspace + \"\\\\Lab3.sde\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
